# 第四次课

## 上次课回顾
金钱使人幸福

k个 nearestNeigbower

## 机器学习主要挑战：数据，算力，模型

数据集：训练&验证&测试模型

经典数据集（iris）：鸢尾花

sklearn or tensorflow
## 插播——关于数据

| 表头 | x_1 | x_2 | x_3 |
| ---- | --- | --- | --- |
| -    | -   | -   | -   |
| -    | -   | -   | -   |

机器学习模型主要使用**结构化数据**，即二维数据图片与视频非分结构化数据<br/>

| 术语   | 含义                   |
| ------ | ---------------------- |
| 实例   | 每一行记录为实例       |
| 特征   | 反映对象在某方面的性质 |
| 特征值 | 特征的取值             |
| 标签   | 结果显示               |
| 样例   |

## 第二章
端到端机器学习项目
| 序号 | 主要步骤             |
| ---- | -------------------- |
| 1    | 放眼大局             |
| 2    | 获取数据             |
| 3    | 探索与可视化数据     |
| 4    | 为机器学习准备数据   |
| 5    | 选择一模型并训练     |
| 6    | 微调模型             |
| 7    | 展示解决方案         |
| 8    | 发布，监控，维护系统 |

<font size = "3">有监督学习，回归模型</font>

# 第五次课
## 插播——评价指标解释
评级误差的两种距离方式

| L1范数（曼哈顿距离）       | L2范数(欧几里得距离)           |
| -------------------------- | ------------------------------ |
| 向量的各个分量的绝对值之和 | 向量的各个分量的平方和的平方根 |

$$
\text{RMSE}(X, h) = \sqrt{\frac{1}{m} \sum_{i=1}^{m} \left( x^{(i)}) - y^{(i)} \right)^2 }
$$
>m是你测量RMSE的数据集中的实例数。如你在2000个地区的验证集上评估RMSE，则m=2000。<br/>
$x(i)$是数据集中第i个实例的所有特征值（不包括标签）的向量，<br/>
$y(i)$是它的标签（该实例的期望输出值，或者说就是实际解），<br/>
$h$是系统的预测函数，给定模型一个实例特征向量x(i)时，模型会给出一个预测h(x)，通常也叫y帽。<br/>

## 3探索和可视化数据以获得见解——探索训练集（不看测试集）

### 3.2寻找相关系数
用corr()方法算出每对属性之间标准相关系数（也称为皮尔逊r）
### 3.3实验不同属性组合—
有些属性可能组合起来更有用
## 4.为机器学习算法准备数据
### 4.1 清洗数据——见配套书籍
Scikit-Learn类：SimpleImputer是更佳的选择

>缺失值也可以替换为平均值(strategy="mean")，
或替换为最频繁的值(strategy="most_frequent")，
或替换为常数值(strategy="constant"，fill_value=...)。最后两种策略支持非数值数据。
### 4.2 特征缩放与转换
最小—最大缩放（很多人称之为归一化）：

——对于每个属性，值被移动和重新缩放，这样它们最终值在0～1之间。

——Scikit-Learn为此提供了一个名为MinMaxScaler的转换器
### 插播——Scikit-learn四大组件
![alt text](image-2.png)
### 4.3 转换流水线
以正确的顺序执行许多数据转换步骤。
————Scikit-Learn提供了Pipeline类来帮助处理此类转换序列。
